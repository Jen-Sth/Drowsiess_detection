{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import mediapipe as mp\n",
    "# import time\n",
    "# import numpy as np\n",
    "\n",
    "# # Initialize Mediapipe components\n",
    "# mp_face_mesh = mp.solutions.face_mesh\n",
    "# mp_drawing = mp.solutions.drawing_utils\n",
    "# mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "# # Constants\n",
    "# EAR_THRESHOLD = 0.2  # Threshold for eye aspect ratio\n",
    "# DROWSINESS_FRAMES = 20  # Number of frames to consider for drowsiness\n",
    "# ALERT_TIME = 4  # Time in seconds to trigger alert\n",
    "# ALERT_SOUND_FREQ = 1000  # Frequency for beep sound\n",
    "# ALERT_SOUND_DURATION = 1000  # Duration for beep sound in milliseconds\n",
    "\n",
    "# # Initialize variables\n",
    "# drowsy_frames = 0\n",
    "# start_time = None\n",
    "\n",
    "# def calculate_ear(eye):\n",
    "#     # Calculate the Eye Aspect Ratio (EAR)\n",
    "#     A = np.linalg.norm(eye[1] - eye[5])\n",
    "#     B = np.linalg.norm(eye[2] - eye[4])\n",
    "#     C = np.linalg.norm(eye[0] - eye[3])\n",
    "#     ear = (A + B) / (2.0 * C)\n",
    "#     return ear\n",
    "\n",
    "# def detect_drowsiness(ear):\n",
    "#     global drowsy_frames, start_time\n",
    "#     if ear < EAR_THRESHOLD:\n",
    "#         drowsy_frames += 1\n",
    "#         if drowsy_frames >= DROWSINESS_FRAMES:\n",
    "#             if start_time is None:\n",
    "#                 start_time = time.time()\n",
    "#             elif time.time() - start_time > ALERT_TIME:\n",
    "#                 print(\"DROWSINESS DETECTED! Beep!\")\n",
    "#                 # Uncomment below line to enable beep sound\n",
    "#                 # winsound.Beep(ALERT_SOUND_FREQ, ALERT_SOUND_DURATION)\n",
    "#     else:\n",
    "#         drowsy_frames = 0\n",
    "#         start_time = None\n",
    "\n",
    "# def main():\n",
    "#     cap = cv2.VideoCapture(0)  # Use the default camera\n",
    "#     with mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5) as face_mesh:\n",
    "#         while cap.isOpened():\n",
    "#             ret, frame = cap.read()\n",
    "#             if not ret:\n",
    "#                 break\n",
    "\n",
    "#             frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#             results = face_mesh.process(frame)\n",
    "#             frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "#             if results.multi_face_landmarks:\n",
    "#                 for face_landmarks in results.multi_face_landmarks:\n",
    "#                     # Draw face mesh\n",
    "#                     mp_drawing.draw_landmarks(frame, face_landmarks, mp_face_mesh.FACE_CONNECTIONS)\n",
    "\n",
    "#                     # Get eye landmarks\n",
    "#                     left_eye = np.array([[face_landmarks.landmark[i].x, face_landmarks.landmark[i].y]\n",
    "#                                           for i in range(362, 368)])  # Left eye landmarks\n",
    "#                     right_eye = np.array([[face_landmarks.landmark[i].x, face_landmarks.landmark[i].y]\n",
    "#                                            for i in range(385, 391)])  # Right eye landmarks\n",
    "\n",
    "#                     # Calculate EAR for both eyes\n",
    "#                     ear_left = calculate_ear(left_eye)\n",
    "#                     ear_right = calculate_ear(right_eye)\n",
    "#                     ear = (ear_left + ear_right) / 2.0\n",
    "\n",
    "#                     # Detect drowsiness\n",
    "#                     detect_drowsiness(ear)\n",
    "\n",
    "#             cv2.imshow(\"Driver Monitoring\", frame)\n",
    "\n",
    "#             if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#                 break\n",
    "\n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import mediapipe as mp\n",
    "# import time\n",
    "# import numpy as np\n",
    "\n",
    "# # Initialize Mediapipe components\n",
    "# mp_face_mesh = mp.solutions.face_mesh\n",
    "# mp_drawing = mp.solutions.drawing_utils\n",
    "# mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "# # Constants\n",
    "# EAR_THRESHOLD = 0.2  # Threshold for eye aspect ratio\n",
    "# DROWSINESS_FRAMES = 20  # Number of frames to consider for drowsiness\n",
    "# ALERT_TIME = 4  # Time in seconds to trigger alert\n",
    "# ALERT_SOUND_FREQ = 1000  # Frequency for beep sound\n",
    "# ALERT_SOUND_DURATION = 1000  # Duration for beep sound in milliseconds\n",
    "\n",
    "# # Initialize variables\n",
    "# drowsy_frames = 0\n",
    "# start_time = None\n",
    "\n",
    "# def calculate_ear(eye):\n",
    "#     # Calculate the Eye Aspect Ratio (EAR)\n",
    "#     A = np.linalg.norm(eye[1] - eye[5])\n",
    "#     B = np.linalg.norm(eye[2] - eye[4])\n",
    "#     C = np.linalg.norm(eye[0] - eye[3])\n",
    "#     ear = (A + B) / (2.0 * C)\n",
    "#     return ear\n",
    "\n",
    "# def detect_drowsiness(ear):\n",
    "#     global drowsy_frames, start_time\n",
    "#     if ear < EAR_THRESHOLD:\n",
    "#         drowsy_frames += 1\n",
    "#         if drowsy_frames >= DROWSINESS_FRAMES:\n",
    "#             if start_time is None:\n",
    "#                 start_time = time.time()\n",
    "#             elif time.time() - start_time > ALERT_TIME:\n",
    "#                 print(\"DROWSINESS DETECTED! Beep!\")\n",
    "#                 # Uncomment below line to enable beep sound\n",
    "#                 # winsound.Beep(ALERT_SOUND_FREQ, ALERT_SOUND_DURATION)\n",
    "#     else:\n",
    "#         drowsy_frames = 0\n",
    "#         start_time = None\n",
    "\n",
    "# def main():\n",
    "#     cap = cv2.VideoCapture(0)  # Use the default camera\n",
    "#     with mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5) as face_mesh:\n",
    "#         while cap.isOpened():\n",
    "#             ret, frame = cap.read()\n",
    "#             if not ret:\n",
    "#                 break\n",
    "\n",
    "#             frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#             results = face_mesh.process(frame)\n",
    "#             frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "#             if results.multi_face_landmarks:\n",
    "#                 for face_landmarks in results.multi_face_landmarks:\n",
    "#                     # Draw face mesh\n",
    "#                     mp_drawing.draw_landmarks(frame, face_landmarks, mp_face_mesh.FACE_CONNECTIONS)\n",
    "\n",
    "#                     # Get eye landmarks\n",
    "#                     left_eye = np.array([[face_landmarks.landmark[i].x, face_landmarks.landmark[i].y]\n",
    "#                                           for i in range(362, 368)])  # Left eye landmarks\n",
    "#                     right_eye = np.array([[face_landmarks.landmark[i].x, face_landmarks.landmark[i].y]\n",
    "#                                            for i in range(385, 391)])  # Right eye landmarks\n",
    "\n",
    "#                     # Calculate EAR for both eyes\n",
    "#                     ear_left = calculate_ear(left_eye)\n",
    "#                     ear_right = calculate_ear(right_eye)\n",
    "#                     ear = (ear_left + ear_right) / 2.0\n",
    "\n",
    "#                     # Detect drowsiness\n",
    "#                     detect_drowsiness(ear)\n",
    "\n",
    "#             cv2.imshow(\"Driver Monitoring\", frame)\n",
    "\n",
    "#             if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#                 break\n",
    "\n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
